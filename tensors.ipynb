{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-57, -38, -46, -97,  42,   2])\n",
      "tensor([2, 3, 4, 5])\n",
      "tensor([ 0.0000,  2.5000,  5.0000,  7.5000, 10.0000])\n",
      "tensor([1.2589e+00, 3.7584e+02, 1.1220e+05, 3.3497e+07, 1.0000e+10])\n",
      "tensor([[1., 0., 0., 0., 0.],\n",
      "        [0., 1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0., 0.],\n",
      "        [0., 0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Some utils\n",
    "randint  = torch.randint(-100, 100, (6, ))\n",
    "print(randint)\n",
    "\n",
    "arange = torch.arange(2, 6)\n",
    "print(arange)\n",
    "\n",
    "linspace = torch.linspace(0, 10, steps=5)\n",
    "print(linspace)\n",
    "\n",
    "logspace = torch.logspace(0.1, 10, steps=5)\n",
    "print(logspace)\n",
    "\n",
    "# diagonal matrix\n",
    "eye = torch.eye(5)\n",
    "\n",
    "print(eye)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 428 ms, sys: 40.7 ms, total: 469 ms\n",
      "Wall time: 473 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "zeros = torch.rand(3, 10, 25, 29, 100, 100)\n",
    "# WITH CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "CPU times: user 20 ms, sys: 43.5 ms, total: 63.5 ms\n",
      "Wall time: 64.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)\n",
    "zeros = torch.rand(3, 10, 25, 29, 100, 100, device=device)\n",
    "# WITH GPU! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 0, 1, 1, 1, 1, 0, 0, 1, 0])\n",
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# More utils\n",
    "\n",
    "# Probabilites\n",
    "probabilities = torch.tensor([0.3, 0.3, 0.3])\n",
    "samples  = torch.multinomial(probabilities, num_samples=10, replacement=True)\n",
    "print(samples)\n",
    "\n",
    "# concat \n",
    "tensor = torch.tensor([1, 2])\n",
    "out = torch.cat((tensor, torch.tensor([3])), dim=0)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [0., 1., 1.],\n",
      "        [0., 0., 1.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Triangular matrix \n",
    "\n",
    "# upper\n",
    "out = torch.triu(torch.ones(3, 3))\n",
    "print(out)\n",
    "\n",
    "# lower\n",
    "out = torch.tril(torch.ones(3, 3))\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., -inf, -inf],\n",
      "        [0., 0., -inf],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Masks!\n",
    "out = torch.zeros(3, 3).masked_fill(torch.tril(torch.ones(3, 3)) == 0, float('-inf'))\n",
    "print(out)\n",
    "\n",
    "print(torch.exp(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3])\n",
      "torch.Size([3, 2, 1])\n"
     ]
    }
   ],
   "source": [
    "# Transpose\n",
    "\n",
    "input = torch.zeros(1, 2, 3)\n",
    "print(input.transpose(0, 1).shape)\n",
    "print(input.transpose(0, 2).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Stacked \n",
    "\n",
    "t1  = torch.tensor([1, 2, 3])\n",
    "t2 = torch.tensor([4, 5, 6])\n",
    "t3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "print(torch.stack([t1, t2, t3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0813, 7.7409], grad_fn=<SqueezeBackward4>)\n"
     ]
    }
   ],
   "source": [
    "# Linear layer?Â \n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "sample = torch.tensor([10., 10., 10.])\n",
    "linear = nn.Linear(3, 2, bias=False)\n",
    "print(linear(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8.1940e-40, 1.9287e-22, 1.0000e+00])\n"
     ]
    }
   ],
   "source": [
    "# Softmax function apply\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "t1 = torch.tensor([10., 50., 100.])\n",
    "softmax_out = F.softmax(t1, dim=0)\n",
    "\n",
    "print(softmax_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 24])\n"
     ]
    }
   ],
   "source": [
    "# Embeding layer\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "vocab_size = 24\n",
    "embedding_dim = vocab_size\n",
    "embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "input_indices = torch.LongTensor([1, 5, 3, 2])\n",
    "embbeded_out= embedding(input_indices)\n",
    "\n",
    "# this should be (4, 24). 4 for the input size, 24 for vocab_size, like a one hot encoding. \n",
    "print(embbeded_out.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 9, 12, 15],\n",
      "        [19, 26, 33],\n",
      "        [29, 40, 51]])\n"
     ]
    }
   ],
   "source": [
    "# Matrix multiplication\n",
    "\n",
    "a = torch.tensor([[1, 2], [3, 4],[5, 6]])\n",
    "b = torch.tensor(([1, 2, 3], [4, 5,6]))\n",
    "\n",
    "c = a @ b\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
