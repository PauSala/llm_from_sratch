{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from music21 import *\n",
    "\n",
    "# Get all Bach chorale files\n",
    "bach_chorales = corpus.getComposer('bach')\n",
    "\n",
    "# File to store the results\n",
    "output_file = 'data/preprocess.txt'\n",
    "subdivision = 0.5\n",
    "\n",
    "with open(output_file, 'w') as f:\n",
    "    for chorale in bach_chorales:\n",
    "        try:\n",
    "            s = corpus.parse(chorale)\n",
    "            k = s.analyze('key')\n",
    "            \n",
    "            if k.mode == 'minor':\n",
    "                target_key =  pitch.Pitch('A')  # Transpose to A if the key is minor\n",
    "            else:\n",
    "                target_key =  pitch.Pitch('C')  # Transpose to C if the key is major\n",
    "            i = interval.Interval(k.tonic, target_key)\n",
    "            s = s.transpose(i)\n",
    "            # print(f'Key: {s.analyze('key')}')\n",
    "\n",
    "            parts = s.parts\n",
    "            if len(parts) > 4: \n",
    "                continue\n",
    "            measure = parts[0].getElementsByClass('Measure')[0]  \n",
    "\n",
    "            time_signature = measure.timeSignature\n",
    "            measure_length = measure.quarterLength\n",
    "            # print(f'Time signature: {time_signature} | measure_length: {measure_length}')\n",
    "\n",
    "            if measure_length == 1:\n",
    "                measure_length = 4 \n",
    "\n",
    "            num_slots = int(measure_length / subdivision)\n",
    "            data = []\n",
    "\n",
    "            for measure_index in range(len(parts[0].getElementsByClass('Measure'))):\n",
    "                shape = (1, num_slots, len(parts))\n",
    "                out = np.empty(shape, dtype=object)\n",
    "                \n",
    "                for part_index, part in enumerate(parts):\n",
    "                    measure = part.measure(measure_index + 1)\n",
    "                    if measure is not None:\n",
    "                        offset = 0.0\n",
    "                        count = 0\n",
    "                        while offset < measure_length:\n",
    "                            # Iterate over both notes and rests in the measure\n",
    "                            element = next((el for el in measure.notesAndRests if el.offset == offset), None)\n",
    "                            \n",
    "                            if element:\n",
    "                                if isinstance(element, note.Note):  # Handle note\n",
    "                                    token = f\"p{part_index}{element.nameWithOctave}\"\n",
    "                                elif isinstance(element, note.Rest):  # Handle rest\n",
    "                                    token = f\"p{part_index}|\"\n",
    "                                \n",
    "                                # Check for fermata\n",
    "                                for exp in element.expressions:\n",
    "                                    if isinstance(exp, expressions.Fermata):\n",
    "                                        token += 'Â·'\n",
    "                                \n",
    "                                out[0][count][part_index] = token\n",
    "                            else:\n",
    "                                out[0][count][part_index] = f\"p{part_index}\"\n",
    "                            \n",
    "                            # Move the offset forward by 0.25 (quarter note duration)\n",
    "                            offset += subdivision\n",
    "                            count += 1\n",
    "                if np.all(out.flatten() == None):\n",
    "                    continue\n",
    "                else:\n",
    "                    data.extend(out.flatten())  # Add to data if not all are None\n",
    "            # Write to file\n",
    "            f.write(\" \".join(data) + \"\\n\" )\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {chorale}: {e}\")\n",
    "            continue  # Skip to the next chorale if an error occurs\n",
    "\n",
    "        print(f\"Processing {chorale} \")\n",
    "\n",
    "print(f\"Processing complete. Data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "# Read the file and build a vocabulary set\n",
    "char_set = set()\n",
    "\n",
    "with open('data/preprocess.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        split = line.split()\n",
    "        for token in split:\n",
    "            char_set.add(token)  # Add each unique token to the set\n",
    "\n",
    "# Create mappings\n",
    "string_to_int = {token: idx for idx, token in enumerate(char_set)}\n",
    "int_to_string = {idx: token for token, idx in string_to_int.items()}\n",
    "\n",
    "# Encoding and decoding functions\n",
    "encode = lambda s: [string_to_int[c] for c in s]\n",
    "decode = lambda l: ' '.join([int_to_string[i] for i in l]) \n",
    "\n",
    "data = [];\n",
    "dict = {};\n",
    "# Open and read the file\n",
    "with open('data/preprocess.txt', 'r') as file:\n",
    "    i = 0\n",
    "    for line in file:\n",
    "        data.extend(encode(line.split()))\n",
    "        dict[i] = torch.tensor(encode(line.split()), dtype=torch.int64)\n",
    "        data.extend(encode(line.split()))\n",
    "        i += 1\n",
    "\n",
    "\n",
    "data = torch.tensor(data, dtype=torch.int64)\n",
    "vocab_size = len(char_set)\n",
    "print(len(data))\n",
    "print(len(dict))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtobach.training import Batch_provider\n",
    "from backtobach.model import GPTLanguageModel, device, learning_rate, block_size, batch_size\n",
    "\n",
    "\n",
    "batch_provider=Batch_provider(\n",
    "    chorales_dict=dict, \n",
    "    merged_chorales=data, \n",
    "    block_size=block_size, \n",
    "    batch_size=batch_size, \n",
    "    device=device)\n",
    "\n",
    "x, y = batch_provider.get_batch('train')\n",
    "first = x[0] \n",
    "first_y = y[0]\n",
    "\n",
    "print(decode(first.tolist()))\n",
    "print(decode(first_y.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from backtobach.model import GPTLanguageModel, device, learning_rate, block_size, batch_size\n",
    "from backtobach.training import Batch_provider, train, eval_iters\n",
    "\n",
    "model = GPTLanguageModel(vocab_size)\n",
    "m = model.to(device)\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "\n",
    "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)\n",
    "train(model=m, batch_provider=Batch_provider(\n",
    "    chorales_dict=dict, \n",
    "    merged_chorales=data, \n",
    "    block_size=block_size, \n",
    "    batch_size=batch_size, \n",
    "    device=device),\n",
    "    optimizer=optimizer,\n",
    "    eval_iters=eval_iters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "context = torch.tensor(encode(['p0C4', 'p1G3', 'p2E3', 'p3C3']))\n",
    "\n",
    "# Reshape to the desired shape (1, 1)\n",
    "context = context.unsqueeze(0) # Adds two dimensions\n",
    "context = context.to(device)\n",
    "\n",
    "print(context)\n",
    "\n",
    "# decode = lambda l: ' '.join([int_to_string[i] for i in l])\n",
    "generated_chars = decode(m.generate(context, max_new_tokens=500)[0].tolist())\n",
    "print(generated_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "with open('gpt-01.pkl', 'wb') as f:\n",
    "    pickle.dump(m, f)\n",
    "torch.save(m.state_dict(), 'bachGPT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import stream, note\n",
    "import re\n",
    "\n",
    "chorale = stream.Score()\n",
    "\n",
    "soprano = stream.Part()\n",
    "alto = stream.Part()\n",
    "tenor = stream.Part()\n",
    "bass = stream.Part()\n",
    "\n",
    "parts = [soprano, alto, tenor, bass];\n",
    "\n",
    "soprano.id = \"Soprano\"\n",
    "alto.id = \"Alto\"\n",
    "tenor.id = \"Tenor\"\n",
    "bass.id = \"Bass\"\n",
    "\n",
    "# pattern = r\"p(\\d+)([A-Ga-g][#-]?\\d+|\\|)-(\\d+\\.\\d+)\"\n",
    "pattern = r\"p(\\d+)([A-Ga-g][#-]?\\d+|\\|)\"\n",
    "pattern2 = r\"p(\\d+)(|)-(\\d+\\.\\d+)\"\n",
    "p2 = r\"p(\\d+)\"\n",
    "\n",
    "with open(\"data/out.txt\", 'r') as f:\n",
    "    for line in f:\n",
    "        tokens = line.split()\n",
    "        for token in tokens:\n",
    "            match = re.match(pattern, token)\n",
    "            if match:\n",
    "                part = int(match.group(1))     \n",
    "                notestr = match.group(2)      \n",
    "                # d = match.group(3)            \n",
    "                # print(f\"Token: {token} -> Part: {part}, Note: {note}, Duration: {duration}\")\n",
    "                if part < 4:\n",
    "                    if notestr == '|':\n",
    "                        n = note.Rest()\n",
    "                    else:\n",
    "                        n = note.Note(notestr, quarterLength=1.0 );\n",
    "                    n.duration.quarterLength = 0.5\n",
    "                    parts[part].append(n)\n",
    "            else:\n",
    "                match = re.match(p2, token)\n",
    "                part = int(match.group(1)) \n",
    "                if part < 4:\n",
    "                    parts[part].append(note.Rest(quarterLength=0.5))\n",
    "\n",
    "chorale.append(parts)\n",
    "chorale.write(\"musicxml\", fp=\"my_chorale.mxl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmfs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
